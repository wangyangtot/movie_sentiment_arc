{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All movie URLs have a correct format.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "This script gets the movie script, movie name, genres and writer, for\n",
    "approximately 1000 scripts, from the website IMSDb.\n",
    "The progression of scraping can be followed on the terminal.\n",
    "Usage:\n",
    "------\n",
    "To execute this script, type in a terminal\n",
    "$ python scraping_script.py\n",
    "Challenges --> choices:\n",
    "-----------------------\n",
    "some scripts are in html, some in pdf (<50) --> pdfs are ignored\n",
    "some html scripts have javascript --> the package requests is not enough,\n",
    "and the package selenium is used instead\n",
    "Files created:\n",
    "--------------\n",
    "in the ../data/scraping/texts folder:\n",
    "    all the scripts which were available in html (one file per movie)\n",
    "in the ../data/scraping folder:\n",
    "    * successful_files.csv: a CSV file with one row for each movie which were\n",
    "      successfully scraped, with in each row:\n",
    "        the name; writer list; genre list; compact name\n",
    "    * movies_pdf_script.csv: a CSV file with one row for each movie which were\n",
    "      not available in html (usually as pdf) with simply the title of the movie\n",
    "    * scraping_error.csv: a list of movies that could not be scraped\n",
    "'''\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "import progressbar\n",
    "from selenium import webdriver\n",
    "#from selenium import webdriver\n",
    "#driver = webdriver.Firefox(executable_path = '/Users/sethkillian/anaconda/bin/geckodriver')\n",
    "s = requests.session()\n",
    "s.keep_alive = False\n",
    "\n",
    "def get_all_movies():\n",
    "    '''\n",
    "    Scrape 'http://www.imsdb.com/all%20scripts/' to extract the list of\n",
    "    available scripts on IMSDb and the URL at which to access them.\n",
    "    Returns:\n",
    "    --------\n",
    "    movie list: list of tuples\n",
    "        each tuple contains:\n",
    "        (movie title, link to movie page, movie_title)\n",
    "        movie page: string with space and commas\n",
    "        link: string href= ...\n",
    "        movie_title: title with the whitespaces as _, name cropped at '.' or ','\n",
    "    ex1:\n",
    "    (u'10 Things I Hate About You',\n",
    "    u'/Movie Scripts/10 Things I Hate About You Script.html',\n",
    "    u'10_Things_I_Hate_About_You')\n",
    "    ex2:\n",
    "    (u'Abyss, The', u'/Movie Scripts/Abyss, The Script.html', u'Abyss')\n",
    "    '''\n",
    "    # Parse the page http://www.imsdb.com/all%20scripts/ with beautiful soup\n",
    "    link_all_scripts = 'http://www.imsdb.com/all%20scripts/'\n",
    "    response_all_scripts = requests.get(link_all_scripts)\n",
    "    soup = BeautifulSoup(response_all_scripts.text, 'html.parser')\n",
    "\n",
    "    # This webpage is constructed with tables, the 3rd one is the one we want\n",
    "    find_tables = soup.findAll('td', valign='top')\n",
    "    all_movies = find_tables[2].findAll('a')\n",
    "\n",
    "    # Example of item in list all_movies\n",
    "    # <a href=\"/Movie Scripts/10 Things I Hate About You Script.html\"\n",
    "    # title=\"10 Things I Hate About You Script\">10 Things I Hate About You</a>\n",
    "\n",
    "    # Build the final list of tuples, which is to be returned\n",
    "    movies = [(movie_info.string, \\\n",
    "              movie_info[\"href\"], \\\n",
    "              re.split(\"[,.]\",movie_info.string)[0].replace(' ', '_'))\n",
    "              for movie_info in all_movies]\n",
    "    return movies\n",
    "\n",
    "def check_movie_info(movies):\n",
    "    '''\n",
    "    Check that the list of tuples (movie title, link, movie_title)\n",
    "    in movies have a link that start with '/Movie Scripts/'\n",
    "    Parameter\n",
    "    ---------\n",
    "    movies: list of tuples\n",
    "        A list returned by the function `get_all_movies`\n",
    "    Returns\n",
    "    -------\n",
    "    A string that indicates whether there was a problem or not\n",
    "    '''\n",
    "    for movie in movies:\n",
    "        if movie[1][0:15] !='/Movie Scripts/':\n",
    "            return 'One of the movie link does not start with /Movie Scripts/.'\n",
    "    return 'All movie URLs have a correct format.'\n",
    "\n",
    "def handle_movie (movie, browser):\n",
    "    '''\n",
    "    Download the script corresponding to `movie`, using selenium\n",
    "    Parameters\n",
    "    ----------\n",
    "    movie: tuple\n",
    "        a tuple from the `movies` list created by `get_all_movies`\n",
    "            (movie title, link to movie page, movie_title)\n",
    "    browser: object\n",
    "        the browser used by selenium to get complete html page\n",
    "    '''\n",
    "    # Unpack tuple\n",
    "    title, link_to_movie_page, movie_title = movie\n",
    "\n",
    "    # Interrogate the page with all the movie information (ratings, writer,\n",
    "    # genre, link to script)\n",
    "    full_html_link = u'http://www.imsdb.com' + link_to_movie_page\n",
    "    response_script = requests.get(full_html_link)\n",
    "    soup = BeautifulSoup(response_script.text, 'html.parser')\n",
    "\n",
    "    # Get all relevant information (genre, writer, script) from page\n",
    "    list_links = soup.findAll('table', \"script-details\")[0].findAll('a')\n",
    "    genre = []\n",
    "    writer = []\n",
    "    script = ''\n",
    "    for link in list_links:\n",
    "        href = link['href']\n",
    "        if href[0:7]== \"/writer\":\n",
    "            writer.append(link.get_text())\n",
    "        if href[0:7]== \"/genre/\":\n",
    "            genre.append(link.get_text())\n",
    "        if href[0:9]== \"/scripts/\":\n",
    "            script = href\n",
    "\n",
    "    # If the link to the script points to a PDF, skip this movie, but log\n",
    "    # the information in `movies_pdf_script.csv`\n",
    "    if script == '' or script[-5:] != '.html':\n",
    "        path_to_directory = '../data/scraping/'\n",
    "        pdf_logging_filename = path_to_directory + 'movies_pdf_script.csv'\n",
    "        with open(pdf_logging_filename, 'a') as f:\n",
    "            new_row = title + '\\n'\n",
    "            f.write(new_row)\n",
    "\n",
    "    # If the link to the script points to an html page, write the corresponding\n",
    "    # text to a file and include the movie in a csv file, with meta-information\n",
    "    else:\n",
    "\n",
    "        # Parse the webpage which contains the script text\n",
    "        full_script_url =  u'http://www.imsdb.com' + script\n",
    "        browser.get(full_script_url)\n",
    "        page_text = browser.page_source\n",
    "        soup = BeautifulSoup(page_text, 'html.parser')\n",
    "\n",
    "        # If the scraping does not go as planned (unexpected structure),\n",
    "        # log the file name in an error file\n",
    "        if len(soup.findAll('td', \"scrtext\"))!=1:\n",
    "            error_file_name = '../data/scraping/scraping_error.csv'\n",
    "            with open(error_file_name, 'a') as error_file:\n",
    "                new_row = title + '\\n'\n",
    "                error_file.write( new_row )\n",
    "\n",
    "        # Normal scraping:\n",
    "        else:\n",
    "            # Write the script text to a file\n",
    "            path_to_directory = '../data/scraping/texts/'\n",
    "            filename = path_to_directory + movie_title + '.txt'\n",
    "            text = soup.findAll('td', \"scrtext\")[0].get_text()\n",
    "            with codecs.open(filename, \"w\",\n",
    "                    encoding='ascii', errors='ignore') as f:\n",
    "                f.write(text)\n",
    "\n",
    "            # Add the meta-information to a CSV file\n",
    "            path_to_directory = '../data/scraping/'\n",
    "            success_filename = path_to_directory + 'successful_files.csv'\n",
    "            new_row = title + ';' + str(genre) + ';' + str(writer) + ';' \\\n",
    "                    + movie_title + ';' + filename + '\\n'\n",
    "            with open(success_filename, 'a') as f:\n",
    "                f.write(new_row)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Create data/scraping/texts files\n",
    "    if not os.path.exists('../data'):\n",
    "        os.mkdir('../data')\n",
    "        print 'making ../data folder'\n",
    "    if not os.path.exists('../data/scraping'):\n",
    "        os.mkdir('../data/scraping')\n",
    "        print 'making ../data/scraping folder'\n",
    "    if not os.path.exists('../data/scraping/texts'):\n",
    "        os.mkdir('../data/scraping/texts')\n",
    "        print 'making ../data/scraping/texts folder'\n",
    "\n",
    "    # List all the available movies, and the corresponding URL links\n",
    "    movies = get_all_movies()\n",
    "    print check_movie_info(movies)\n",
    "\n",
    "    # Write all the scripts (in texts folder) and the summary of the movies\n",
    "    # in .csv format (in scraping folder)\n",
    "    browser = webdriver.Firefox()\n",
    "    for i,movie in enumerate(movies):\n",
    "        handle_movie(movie, browser)\n",
    "        #progressionbar(i, len(movies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
